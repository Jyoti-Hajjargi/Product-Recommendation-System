# -*- coding: utf-8 -*-
"""Product Recommendation System

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jCQeOX5PopNBPseDjEwCvoe7W6oJOjqB
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)


import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# Libraries
import numpy as np
import polars as pl
import seaborn as sns
import matplotlib.pyplot as plt

# Read the CSV files
events = pl.read_csv("/content/events.csv")
category_tree = pl.read_csv("/content/category_tree.csv")
item_properties_part1 = pl.read_csv("/content/item_properties_part1.csv")
item_properties_part2 = pl.read_csv("/content/item_properties_part2.csv")

# Combine item_properties into a single DataFrame
item_properties = pl.concat([item_properties_part1, item_properties_part2], how="vertical")
events_copy = events.clone()

# Print summaries to verify
print("Events DataFrame:")
print(events.head())

print("\nCategory Tree DataFrame:")
print(category_tree.head())

print("\nItem Properties DataFrame (Combined):")
print(item_properties.head())

print(events.schema, "\n")
print(category_tree.schema,  "\n")
print(item_properties.schema,  "\n")

print(events.null_count())
print(category_tree.null_count())
print(item_properties.null_count())

"""Get summary statistics:"""

events.describe()

item_properties.describe()

event_counts = events.group_by("event").agg(pl.count("event").alias("count"))

# Convert Polars DataFrame to Pandas DataFrame
event_counts_df = event_counts.to_pandas()

# Set Seaborn style
sns.set(style="whitegrid")

# Create the bar plot
plt.figure(figsize=(8, 6))
sns.barplot(data=event_counts_df, x="event", y="count", palette="viridis")

# Add title and labels
plt.title("Event Distribution", fontsize=16)
plt.xlabel("Event Type", fontsize=12)
plt.ylabel("Count", fontsize=12)

# Show the plot
plt.show()

total_views = events.filter(pl.col("event") == "view").shape[0]

# Step 2: Aggregate counts for all events
event_counts = (
    events.group_by("event")
    .agg(pl.count("event").alias("count"))
    .with_columns(
        # Step 3: Add percentage column
        (pl.col("count") / total_views * 100).alias("percent_of_purchases")
    )
)


print(event_counts)
print( np.round( event_counts["percent_of_purchases"], 2))

top_customers = (
    events.filter(pl.col("event") == "transaction")
    .group_by("visitorid")
    .agg(pl.count("event").alias("purchase_count"))
    .sort("purchase_count", descending=True)
)

# Convert Polars DataFrame to Pandas DataFrame
top_customers_df = top_customers.to_pandas()

# Plot Histogram with Logarithmic y-axis
plt.figure(figsize=(10, 6))
sns.histplot(
    top_customers_df["purchase_count"],
    bins=100,
    kde=False,
    color="blue"
)
plt.yscale("log")
plt.title("Distribution of Purchase Counts (Log Scale)", fontsize=14)
plt.xlabel("Purchase Count", fontsize=12)
plt.ylabel("Log(Frequency)", fontsize=12)
plt.grid(axis='y')
plt.show()

# Sort by purchase_count
top_n = top_customers_df.nlargest(20, "purchase_count")

# Plot Pareto Chart
plt.figure(figsize=(12, 6))
sns.barplot(
    x=top_n["visitorid"].astype(str),
    y=top_n["purchase_count"],
    palette="Blues_r"
)
plt.title("Top 20 Customers by Purchase Count", fontsize=14)
plt.xlabel("Visitor ID", fontsize=12)
plt.ylabel("Purchase Count", fontsize=12)
plt.xticks(rotation=45)
plt.show()

# Assuming 'events' is a Polars DataFrame
events = events.with_columns(pl.col("timestamp").cast(pl.Datetime))
purchase_times = (
    events.filter(pl.col("event") == "transaction")
    .with_columns(pl.col("timestamp").dt.hour().alias("hour"))  # Ensure .hour() is used as a method
    .group_by("hour")
    .agg(pl.count("event").alias("purchase_count"))
    .sort("hour")
)
print(purchase_times)

purchase_times_dict = purchase_times.to_pandas().set_index("hour")["purchase_count"].to_dict()

plt.figure(figsize=(10, 6))
plt.plot(list(purchase_times_dict.keys()), list(purchase_times_dict.values()), marker='o', color='green')
plt.title("Peak Purchase Times", fontsize=14)
plt.xlabel("Hour of Day", fontsize=12)
plt.ylabel("Number of Purchases", fontsize=12)
plt.grid()
plt.show()

journey = (
    events.group_by(["visitorid", "event"])
    .agg(pl.count("event").alias("count"))
    .pivot(
        values="count",
        index="visitorid",
        columns="event",
        aggregate_function="sum",
    )
    .fill_null(0)
)
print(journey)

top_products = (
    events.filter(pl.col("event") == "transaction")
    .group_by("itemid")
    .agg(pl.count("event").alias("purchase_count"))
    .sort("purchase_count", descending=True)
)
print(top_products)


top_products_df = top_products.head(10).to_pandas()
plt.figure(figsize=(12, 6))
plt.bar(top_products_df["itemid"].astype(str), top_products_df["purchase_count"], color='orange')
plt.title("Top 10 Selling Products", fontsize=14)
plt.xlabel("Product ID", fontsize=12)
plt.ylabel("Number of Purchases", fontsize=12)
plt.xticks(rotation=45)
plt.show()

events_with_properties = events.join(
    item_properties.filter(pl.col("property") == "categoryid"),
    on="itemid",
    how="inner",
)
category_popularity = (
    events_with_properties.group_by("value")  # value = categoryid
    .agg(pl.count("event").alias("event_count"))
    .sort("event_count", descending=True)
)
print(category_popularity)



category_popularity_df = category_popularity.head(10).to_pandas()
plt.figure(figsize=(12, 6))
plt.bar(category_popularity_df["value"].astype(str), category_popularity_df["event_count"], color='purple')
plt.title("Top 10 Popular Categories", fontsize=14)
plt.xlabel("Category ID", fontsize=12)
plt.ylabel("Event Count", fontsize=12)
plt.xticks(rotation=45)
plt.show()

product_trends = (
    events_copy.filter(pl.col("event") == "transaction")  # Ensure the event name is correct
    .with_columns(
        pl.col("timestamp")
        .cast(pl.Datetime("ms"))  # Convert Unix timestamp (milliseconds) to datetime
        .dt.date()
        .alias("date")
    )
    .group_by(["date", "itemid"])  # Correct spelling of `groupby`
    .agg(pl.count("event").alias("daily_sales"))
    .sort(["date", "daily_sales"], descending=True)
)
print(product_trends)

# Convert to pandas
product_trends_df = product_trends.to_pandas()

# Sort the data by date for better plotting
product_trends_df = product_trends_df.sort_values("date")

# Get the top 5 items by total sales
sales_daily = product_trends_df.groupby("date")["daily_sales"].sum()[:-1]

# Plot the trends
plt.figure(figsize=(12, 5))
plt.plot( sales_daily)

plt.title("Sales Trends", fontsize=14)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Sales", fontsize=12)
plt.legend()
plt.grid()
plt.show()